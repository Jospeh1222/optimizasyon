# ğŸ§  Optimizasyon AlgoritmalarÄ±nÄ±n KarÅŸÄ±laÅŸtÄ±rÄ±lmasÄ± (C)

Bu proje, **Gradient Descent (GD)**, **Stochastic Gradient Descent (SGD)** ve **Adam** optimizasyon algoritmalarÄ±nÄ± bir sÄ±nÄ±flandÄ±rma problemi Ã¼zerinde karÅŸÄ±laÅŸtÄ±rmak amacÄ±yla geliÅŸtirilmiÅŸtir.  
MNIST Fashion veri seti kullanÄ±larak, sÄ±nÄ±flandÄ±rma baÅŸarÄ±mÄ± ve eÄŸitim sÃ¼reÃ§leri analiz edilmiÅŸtir.

---

## ğŸ“š Ä°Ã§indekiler
- [ğŸ“Œ Proje Ã–zeti](#-proje-Ã¶zeti)
- [ğŸ“Š KullanÄ±lan Veri Seti](#-kullanÄ±lan-veri-seti)
- [âš™ï¸ KullanÄ±lan Parametreler](#ï¸-kullanÄ±lan-parametreler)
- [ğŸ§  Algoritmalar](#-algoritmalar)
- [ğŸ› ï¸ Kurulum](#-kurulum)
- [â–¶ï¸ Ã‡alÄ±ÅŸtÄ±rma](#ï¸-Ã§alÄ±ÅŸtÄ±rma)
- [ğŸ“ˆ SonuÃ§lar & Grafikler](#-sonuÃ§lar--grafikler)
- [ğŸ“½ï¸ Video AÃ§Ä±klamasÄ±](#ï¸-video-aÃ§Ä±klamasÄ±)
- [ğŸ‘¨â€ğŸ’» GeliÅŸtirici](#-geliÅŸtirici)
- [ğŸ“„ Lisans](#-lisans)

---

## ğŸ“Œ Proje Ã–zeti

- ğŸ“ **AmaÃ§:** FarklÄ± optimizasyon algoritmalarÄ±nÄ±n eÄŸitim performanslarÄ±nÄ± ve doÄŸruluk oranlarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rmak.  
- ğŸ’» **Dil:** C  
- ğŸ§® **YapÄ±:** Projede veri okuma, aktivasyon, ileri besleme, aÄŸÄ±rlÄ±k gÃ¼ncelleme ve deÄŸerlendirme adÄ±mlarÄ± yer alÄ±r.  
- ğŸ§  **Algoritmalar:** Gradient Descent, Stochastic Gradient Descent, Adam  
- ğŸ“ **SonuÃ§lar:** Her algoritma iÃ§in loss (kayÄ±p) deÄŸerleri dosyaya yazÄ±lÄ±r, doÄŸruluk oranÄ± hesaplanÄ±r ve epoch-loss grafikleri Ã§izilebilir.

---

## ğŸ“Š KullanÄ±lan Veri Seti

Proje, **Fashion MNIST** veri setinin 28Ã—28 piksellik gri tonlu gÃ¶rÃ¼ntÃ¼lerinden oluÅŸturulan bir alt kÃ¼mesini kullanÄ±r:

- ğŸ‘Ÿ **Sneaker** sÄ±nÄ±fÄ± â†’ 1250 Ã¶rnek  
- ğŸ‘— **Dress** sÄ±nÄ±fÄ± â†’ 1250 Ã¶rnek  
- Toplam veri sayÄ±sÄ±: **2500**
- EÄŸitim/Test oranÄ±: %80 eÄŸitim / %20 test

Veriler `.csv` formatÄ±nda okunur, etiketler yalnÄ±zca â€œ3â€ (sneaker, +1) ve â€œ7â€ (dress, -1) olacak ÅŸekilde filtrelenir.

---

## âš™ï¸ KullanÄ±lan Parametreler

| Parametre | AÃ§Ä±klama |
|-----------|----------|
| `N` | GÃ¶rÃ¼ntÃ¼ boyutu (28) |
| `PIXELS` | 28Ã—28 = 784 |
| `DATA_SIZE` | 2500 |
| `TRAIN_RATIO` | 0.8 |
| `LEARNING_RATE` | Ã–ÄŸrenme oranÄ± |
| `EPOCHS` | EÄŸitim dÃ¶ngÃ¼sÃ¼ sayÄ±sÄ± |
| `BETA1, BETA2, EPSILON` | Adam iÃ§in hiperparametreler |

---

## ğŸ§  Algoritmalar

### 1ï¸âƒ£ Gradient Descent (GD)
- TÃ¼m veri seti Ã¼zerinden tek seferde gradyan hesaplanÄ±r.  
- Sabit Ã¶ÄŸrenme oranÄ± ile aÄŸÄ±rlÄ±klar gÃ¼ncellenir.  
- Paralel gÃ¼ncelleme yapÄ±sÄ± sayesinde simetrik bir aÄŸÄ±rlÄ±k uzayÄ± izler.

### 2ï¸âƒ£ Stochastic Gradient Descent (SGD)
- Her adÄ±mda rastgele bir Ã¶rnek seÃ§ilir.  
- Mini-batch yerine tek Ã¶rnekle gÃ¼ncelleme yapÄ±lÄ±r.  
- AÄŸÄ±rlÄ±k uzayÄ±nda farklÄ± bÃ¶lgelerin optimize edilmesini saÄŸlar.

### 3ï¸âƒ£ Adam
- Momentum ve adaptif Ã¶ÄŸrenme oranÄ± kullanÄ±r.  
- `m` (hareketli ortalama) ve `v` (kare ortalama) hesaplanÄ±r.  
- Bias dÃ¼zeltmesi yapÄ±larak aÄŸÄ±rlÄ±klar gÃ¼ncellenir.

---

## ğŸ› ï¸ Kurulum

1. Projeyi klonla:
```bash
git clone https://github.com/kullaniciadi/optimizasyon-algoritmalari-c.git
cd optimizasyon-algoritmalari-c
```

2. Derle:
```bash
gcc main.c -o optimizasyon -lm
```

> `-lm` bayraÄŸÄ± matematik fonksiyonlarÄ± iÃ§in gereklidir.

---

## â–¶ï¸ Ã‡alÄ±ÅŸtÄ±rma

Veri dosyasÄ±nÄ±n (`fashion_mnist_subset.csv` vb.) proje dizininde olduÄŸundan emin olun.

```bash
./optimizasyon
```

Program sÄ±rasÄ±yla:

1. Veriyi yÃ¼kler ve eÄŸitim/test kÃ¼melerine ayÄ±rÄ±r  
2. AÄŸÄ±rlÄ±klarÄ± rastgele baÅŸlatÄ±r  
3. GD, SGD ve Adam algoritmalarÄ±nÄ± ayrÄ± ayrÄ± Ã§alÄ±ÅŸtÄ±rÄ±r  
4. Her birinin **loss deÄŸerlerini** kaydeder  
5. Test doÄŸruluÄŸunu hesaplar  
6. SonuÃ§larÄ± `.csv` dosyalarÄ±na yazar

---

## ğŸ“ˆ SonuÃ§lar & Grafikler

EÄŸitim sÄ±rasÄ±nda loss deÄŸerleri epoch bazÄ±nda kaydedilir. Bu veriler kullanÄ±larak Ã§izilen bazÄ± grafik Ã¶rnekleri ğŸ‘‡

### Epoch vs Loss  
Her algoritma iÃ§in epoch sayÄ±sÄ±na gÃ¶re loss eÄŸrileri Ã§izilir.

### t-SNE GÃ¶rselleÅŸtirmesi  
AÄŸÄ±rlÄ±klarÄ±n optimizasyon sÃ¼recindeki evrimi t-SNE yÃ¶ntemiyle 2B dÃ¼zleme indirgenerek gÃ¶rselleÅŸtirilmiÅŸtir.  
- SGD â†’ farklÄ± dallara ayrÄ±lan aÄŸÄ±rlÄ±k gruplarÄ±  
- Adam â†’ 4 kÃ¼meye ayrÄ±ÅŸmÄ±ÅŸ net bÃ¶lgeler  
- GD â†’ yÄ±ldÄ±z biÃ§iminde simetrik yapÄ±

---

## ğŸ“½ï¸ Video AÃ§Ä±klamasÄ±

Kodu anlatan video:  
ğŸ‘‰ [YouTube - Optimizasyon AlgoritmalarÄ± AÃ§Ä±klama](https://www.youtube.com/watch?v=qH5uKz3aNZU)

---

## ğŸ‘¨â€ğŸ’» GeliÅŸtirici

**Yusuf BaÅŸar GÃ¼ndÃ¼z**  
ğŸ“§ basar.gunduz@std.yildiz.edu.tr  
ğŸ“ YÄ±ldÄ±z Teknik Ãœniversitesi - Bilgisayar MÃ¼hendisliÄŸi
